---
layout: post
comments: true
title:  "Bài 14: Giới thiệu về Multi-layer Perceptrons (Feedforward Neural Networks)"
date:   2017-02-17 15:22:00
permalink: 2017/02/24/mlp/
mathjax: true
tags: Neural-nets Multi-layer
category: Neural-nets
sc_project:
sc_security:
img: \assets\13_softmax\softmax_nn.png
summary: Giới thiệu về Neural Networks nhiều lớp (multi-layer perceptrons)
---

**Trong trang này:**

<!-- MarkdownTOC -->

- [Giới thiệu](#gioi-thieu)
    - [Biểu diễn hàm XOR với Neural Network.](#bieu-dien-ham-xor-voi-neural-network)
- [Các ký hiệu và khái niệm](#cac-ky-hieu-va-khai-niem)
    - [Layers](#layers)
    - [Units](#units)
    - [Weights và Biases](#weights-va-biases)
    - [Activation functions](#activation-functions)
        - [Hàm _sgn_ không được sử dụng trong MLP](#ham-sgn-khong-duoc-su-dung-trong-mlp)
        - [Sigmoid và tanh](#sigmoid-va-tanh)
    - [ReLU](#relu)
        - [Một vài lưu ý](#mot-vai-luu-y)
- [Backpropagation](#backpropagation)
    - [Backpropagation cho một cặp điểm dữ liệu](#backpropagation-cho-mot-cap-diem-du-lieu)
- [Tài liệu tham khảo](#tai-lieu-tham-khao)

<!-- /MarkdownTOC -->

<a name="gioi-thieu"></a>

## Giới thiệu

Bài toán [Supervised Learning](/2016/12/27/categories/#supervised-learning-hoc-co-giam-sat), nói một cách ngắn gọn, là việc đi tìm một hàm số để với mỗi _input_, ta sử dụng hàm số đó để dự đoán _output_. Hàm số này được xây dựng dựa trên các cặp dữ liệu \\((\mathbf{x}\_1, \mathbf{y}\_i)\\) trong _training set_. _Đầu ra dự đoán_(predicted output) gần với _đầu ra thực sự_(ground truth) thì đó được gọi là một thuật toán tốt (nhưng khi _đầu ra dự đoán_ quá giống với _đầu ra thực sự_ thì không hẳn đã tốt, tôi sẽ đề cập kỹ về hiện tượng trong bài tiếp theo).

Chúng ta cùng xét khả năng biểu diễn (representation) của [Perceptron Learning Algorithm (PLA)](/2017/01/21/perceptron/) cho các bài toán binary vô cùng đơn giản: biểu diễn các hàm số logic NOT, AND, OR, và [XOR](https://en.wikipedia.org/wiki/Exclusive_or) (output bằng 1 nếu và chỉ nếu hai input khác nhau). Để có thể sử dụng PLA (output là 1 hoặc -1), chúng ta sẽ thay các giá trị bằng 0 của output của các hàm này bởi -1. Trong hàng trên của Hình 1 dưới đây, các điểm hình vuông màu xanh là các điểm có label bằng 1, các điểm hình tròn màu đỏ là các điểm có label bằng -1. Hàng dưới của Hình 1 là các mô hình perceptron với các hệ số tương ứng.

<hr>
<div class="imgcap">
 <img src ="/assets/14_mlp/logic_nn.png" align = "center" width = "800">
 <div class = "thecap"> Hình 1: PLA biểu diễn các hàm logic đơn giản. </div>
</div>
<hr>
 Nhận thấy rằng với các bài toán OR, AND, và OR, dữ liệu là [_linearly separable_](/2017/01/21/perceptron/#bai-toan-perceptron), vì vậy ta có thể tìm được các hệ số cho perceptron giúp biểu diễn chính xác cho mỗi hàm số. Xem ví dụ với hàm NOT, khi \\(x_1 = 0\\), ta có \\(z = \text{sgn}(-2*0+1) = 1\\). Khi \\(x_1 = 1\\), \\(z = \text{sgn}(-2*1 + 1) = -1\\). Trong cả hai trường hợp, predicted output đều giống với [ground truth](/2017/01/08/knn/#ground-truth). Bạn đọc có thể tự kiểm chứng các hệ số trong hình với hàm AND và OR.

<a name="bieu-dien-ham-xor-voi-neural-network"></a>

### Biểu diễn hàm XOR với Neural Network.

Với hàm XOR, vì dữ liệu không _linearly separable_, tức không thể tìm được 1 đường thằng giúp phân chia hai lớp xanh đỏ, nên bài toán vô nghiệm. Nếu thay PLA bằng [Logistic Regression](/2017/01/27/logisticregression/), tức thay hàm activation function từ _sgn_ sang [_sigmoid_](/2017/01/27/logisticregression/#sigmoid-function), ta cũng không tìm được các hệ số thỏa mãn, vì về bản chất, [Logistic Regression cũng chỉ tạo ra các đường biên có dạng tuyến tính](/2017/01/27/logisticregression/#boundary-tao-boi-logistic-regression-co-dang-tuyen-tinh). Như vậy là các mô hình Neural Network chúng ta đã biết không thể biểu diễn được hàm số logic đơn giản này.

Nhận thấy rằng nếu cho phép sử dụng hai đường thẳng, bài toán biểu diễn hàm XOR sẽ được giải quyết như Hình 2 (trái) dưới đây:

<hr>
<div class="imgcap">
 <img src ="/assets/14_mlp/xor_nn.png" align = "center" width = "800">
 <div class = "thecap">Hình 2: Multilayer Perceptron biểu diễn hàm XOR</div>
</div>
<hr>

Các hệ số tương ứng với hai đường thẳng trong Hình 2 (trái) được minh họa trên Hình 2 (phải) tại các node màu lục và lam. Đầu ra \\(v\_1\\) bằng 1 với các điểm nằm về phía (+) của đường thẳng \\(-2x\_1 -2x\_2 +3 = 0\\), bằng -1 với các điểm nằm về phía (-). Tương tự, đầu ra \\(v\_2\\) bằng 1 với các điểm nằm về phía (+) của đường thẳng \\(2x\_1 + 2x\_2 + 1 = 0\\). Như vậy, hai đường thằng này tạo ra hai _đầu ra_ tại các node \\(v\_1, v\_2\\). Vì hàm XOR chỉ có một đầu ra nên ta cần làm thêm một bước nữa: coi \\(v\_1, v\_2\\) như là input của một PLA khác. Trong PLA mới này, input là các node màu lam (đừng quên node bias có giá trị bằng 1), output là các node màu đỏ. Các hệ số được cho trên Hình. Kiểm tra lại một chút, với các điểm hình vuông xanh (hình trái), \\(a^{(1)}\_1 = a^{(1)}\_2 = 1\\), khi đó \\(a^{(2)} = \text{sgn}(1 + 1 - 1) = 1\\). Với các điểm hình tròn đỏ, \\(a^{(1)}\_1 = -a^{(1)}\_2\\), vậy nên \\(a^{(2)} = \text{sgn}(a^{(1)}\_1 + a^{(1)}\_2 - 1) = \text{sgn}(-1) = -1\\). Trong cả hai trường hợp, predicted ouput đều giống với ground truth. Vậy, nếu ta sử dụng 3 PLA (tương ứng với các output \\(a^{(1)}\_1, a^{(1)}\_2, a^{(2)}\\), ta sẽ biểu diễn được hàm XOR.

Ba PLA kể trên được xếp vào hai _layers_. Layer thứ nhất: input - lục, output - lam tím. Layer thứ hai: input - lam tím, output - đỏ. Ở đây, output của layer thứ nhất chính là input của layer thứ hai. Tổng hợp lại ta được một mô hình mà ngoài layer input (lục) và output (đỏ), ta còn có một layer nữa (lam). Mô hình này có tên gọi là Multilayer Perceptron. Layer trung gian ở giữa còn được gọi là _hidden layer_.
(_Tôi chủ ý dùng màu xanh blue cho các node ở layer hidden, nhưng khi convert ảnh .pdf, tạo bởi LaTeX, ra ảnh .png thì màu lam bị chuyển thành hơi tím_).

**Một vài lưu ý:**

* Perceptron Learing Algorithm là một trường hợp của _single-layer neural network_ với [_activation fucntion_](/2017/01/27/logisticregression/#nhac-lai-hai-mo-hinh-tuyen-tinh) là hàm _sgn_. Trong khi đó, Perceptron là tên chung để chỉ các Neural Network với chỉ một input layer và một output tại output layer, không có hidden layer.

* Các _activation function_ có thể là các nonlinear function khác, ví dụ như _sigmoid function_ hoặc [_tanh function_](/2017/01/27/logisticregression/#tanh-function). Các _activation function_ phải là nonlinear (phi tuyến), vì nếu không, nhiều layer hay một layer cũng là như nhau. Ví dụ với hai layer trong Hình 2, nếu _activation function_ là một hàm linear (giả sử hàm \\(f(s) = s\\)), thì cả hai layer có thể được thay bằng một layer với ma trận hệ số \\(\mathbf{W} = \mathbf{W}^{(2)}\mathbf{W}^{(1)}\\).

* Để cho đơn giản, tôi đã sử dụng ký hiệu \\(\mathbf{W}^{(l)T}\\) để thay cho \\((\mathbf{W}^{(l)})^T\\). Trong Hình 2 (phải), tôi sử dụng ký hiệu ma trận \\(\mathf{W}^{(2)}\\) mặc dù đúng ra nó phải là vector là để biểu diễn tổng quát cho trường hợp output layer có thể có nhiều hơn 1 node. Tương tự với bias \\(\mathbf{b}^{(2)}\\).

* Khác với các bài trước về Neural Networks, khi làm việc với Neural Network có nhiều lớp, ta nên tách riêng phần biases và ma trận hệ số ra. Điều này đồng nghĩa với việc vector input \\(\mathbf{x}\\) là ma vector KHÔNG mở rộng.

<a name="cac-ky-hieu-va-khai-niem"></a>

## Các ký hiệu và khái niệm

<a name="layers"></a>

### Layers
Ngoài _Input layers_ và _Output layers_, một Multi-layer Perceptron (MLP) có thể có nhiều _Hidden layers_ ở giữa. Các _Hidden layers_ theo thứ tự từ input layer đến output layer được đánh số thứ thự là _Hidden layer 1_,_ Hidden layer 2_, ... Hình 3 dưới đây là một ví dụ với 2 Hidden layers.

<hr>
<div class="imgcap">
 <img src ="/assets/14_mlp/multi_layers.png" align = "center" width = "400">
 <div class = "thecap">Hình 3: MLP với hai hidden layers (các biases đã bị ẩn).</div>
</div>
<hr>


Số lượng layer trong một MLP được tính bằng số hidden layers cộng với 1. Tức là khi đếm số layers của một MLP, ta không tính input layers. Số lượng layer trong một MLP thường được ký hiệu là \\(L\\). Trong Hình 3 trên đây, \\(L = 3\\).

<a name="units"></a>

### Units
Một một _node_ hình tròn trong một layer được gọi là một unit. Unit ở các input layer, hidden layers, và output layer được lần lượt gọi là input unit, hidden unit, và output unit. Đầu ra của mỗi unit thường được ký hiệu là \\(a\\) (_a_ thể hiện activation, tức giá trị của mỗi unit sau khi ta áp dụng activation function). Đầu ra của unit thứ \\(i\\) trong layer thứ \\(l\\) được ký hiệu là \\(a_i^{(l)}\\). Giả sử thêm rằng số unit trong layer thứ \\(l)\\) (không tính bias) là \\(d^{(l)}\\). Vector biểu diễn output của layer thứ \\(l\\) được ký hiệu là \\(\mathbf{a}^{(l)} \in \mathbb{R}^{d^{(l)}}\\).


<hr>
<div class="imgcap">
 <img src ="/assets/14_mlp/mlp_notation.png" align = "center" width = "600">
 <div class = "thecap">Hình 4: Các ký hiệu sử dụng trong MLP.</div>
</div>
<hr>

<a name="weights-va-biases"></a>

### Weights và Biases
Có \\(L\\) ma trận trọng số cho một MLP có \\(L\\) layers. Các ma trận này được ký hiệu là \\(\mathbf{W}^{(l)}, l = 1, 2, \dots, L\\) trong đó \\(\mathbf{W}^{(l)}\\) thể hiện các _kết nối_ từ layer thứ \\(l-1\\) tới layer thứ \\(l\\) (nếu ta coi input layer là layer thứ \\(0\\)). Cụ thể hơn, phần tử \\(w^{(l)}_{ij}\\) thể hiện kết nối từ node thứ \\(j\\) của layer thứ \\((l-1)\\) tới node từ \\(i\\) của layer thứ \\((l)\\). Các biases của layer thứ \\((l)\\) được ký hiệu là \\(\mathbf{b}^{(l)} \in \mathbb{R}^{d^{(l)}}\\). Các trọng số này được ký hiệu như trên Hình 4. Khi tối ưu một MLP cho một công việc nào đó, chúng ta cần đi tìm các weghts và biases này.

Tập hợp các weights và biases lần lượt được ký hiệu là \\(\mathbf{W}\\) và \\(\mathbf{b}\\).

<a name="activation-functions"></a>

### Activation functions
(Chú yếu được dịch lại từ: [http://cs231n.github.io/neural-networks-1/ ](CS231n Convolutional Neural Networks for Visual Recognition))
Mỗi output của một unit (trừ các input units) được tính dựa vào công thức:
\\[
a_i^{(l)} = f(\mathbf{w}\_i^{(l)T}\mathbf{a}^{(l-1)} + b\_i^{(l)})
\\]

Trong đó \\(f(.)\\) là một (nonlinear) activation function. Ở dạng vector, biểu thức bên trên được viết là:

\\[
\mathbf{a}^{(l)} = f(\mathbf{W}^{(l)T}\mathbf{a}^{(l-1)} + \mathbf{b}^{(l)})
\\]

Khi activation function \\(f(.)\\) được áp dụng cho một ma trận (hoặc vector), ta hiểu rằng nó được áp dụng cho từng thành phần của ma trận đó, rồi các thành phần này được sắp xếp lại đúng theo thứ tự để được một ma trận có kích thước bằng với ma trận input. Trong tiếng Anh, việc áp dụng lên từng phần tử như thế này được gọi là _element-wise_.

<a name="ham-sgn-khong-duoc-su-dung-trong-mlp"></a>

#### Hàm _sgn_ không được sử dụng trong MLP

Hàm _sgn_ (còn gọi là _hard-threshold_) chỉ được sử dụng trong PLA, mang mục đích giáo dục nhiều hơn. Trong thực tế, hàm _sgn_ không được sử dụng vì hai lý do: đầu ra là _discrete_, và đạo hàm tại hầu hết các điểm bằng 0 (trừ điểm 0 không có đạo hàm). Việc đạo hàm bằng 0 này khiến cho các thuật toán gradient-based (ví dụ như [Gradient Descent](/2017/01/12/gradientdescent/_)) không hoạt động!

<a name="sigmoid-va-tanh"></a>

#### Sigmoid và tanh
<hr>
<div>
<table width = "100%" style = "border: 0px solid white">
   <tr >
        <td width="40%" style = "border: 0px solid white">
        <img style="display:block;" width = "100%" src = "/assets/14_mlp/sigmoid.jpeg">
         </td>
        <td width="40%" style = "border: 0px solid white">
        <img style="display:block;" width = "100%" src = "/assets/14_mlp/tanh.jpeg">
        </td>

    </tr>
</table>
<div class = "thecap"> Hình 5: Hàm <i>sigmoid</i> (trái) và <em>tanh</em> (phải). (Nguồn <a href = "http://cs231n.github.io/neural-networks-1/">CS231n Convolutional Neural Networks for Visual Recognition</a>)
</div>
</div>
<hr>

Hàm _sigmoid_ có dạng \\(f(s) = 1/(1 + \exp(-s))\\) với đồ thị như trong Hình 5 (trái). Nếu đầu vào lớn, hàm số sẽ cho đầu ra gần với 1. Với đầu vào nhỏ (rất âm), hàm số sẽ cho đầu ra gần với 0. Hàm số này được sử dụng nhiều trong quá khứ ví có đạo hàm rất _đẹp_. Những năm gần đây, hàm số này ít khi được sử dụng. Nó có một nhược điểm cơ bản:

* _Sigmoid saturate and kill gradients_: Một nhược điểm dễ nhận thấy là khi đầu vào có trị tuyệt đối lớn (rất âm hoặc rất dương), gradient của hàm số này sẽ rất gần với 0. Điều này đồng nghĩa với việc các hệ số tương ứng với unit đang xét sẽ gần như không được cập nhật. Bạn đọc sẽ hiểu rõ hơn phần này trong phần Phương pháp tối ưu.

Hàm _tanh_ cũng có nhược điểm tương tự về việc gradient rất nhỏ với các đầu vào có trị tuyệt đối lớn.

<a name="relu"></a>

### ReLU

<hr>
<div>
<table width = "100%" style = "border: 0px solid white">
   <tr >
        <td width="40%" style = "border: 0px solid white">
        <img style="display:block;" width = "100%" src = "/assets/14_mlp/relu.jpeg">
         </td>
        <td width="40%" style = "border: 0px solid white">
        <img style="display:block;" width = "100%" src = "/assets/14_mlp/alexplot.jpeg">
        </td>

    </tr>
</table>
 <div class = "thecap">Hình 5: Hàm ReLU và tốc độ hội tụ khi so sánh với hàm tanh.</div>
</div>
<hr>
ReLU (Rectified Linear Unit) được sử dụng rộng rãi gần đây vì tính đơn giản của nó. Đồ thị của hàm ReLU được minh họa trên Hình 5 (trái)). Nó có công thức toán học \\(f(s) = \max(0, s)\\) - rất đơn giản. Ưu điểm chính của nó là:

* ReLU được chứng minh giúp cho việc training các _Deep Networks_ nhanh hơn rất nhiều (theo [Krizhevsky et al.](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)). Hình 5 (phải) so sánh sự hội tụ của SGD khi sử dụng hai activation function khác nhau: ReLU và tanh. Sự tăng tốc này được cho là vì ReLU được tính toán gần như tức thời và gradient của nó cũng được tính cực nhanh với gradient bằng 1 nếu đầu vào lớn hơn 0, bằng 0 nếu đầu vào nhỏ hơn 0.

* Mặc dù hàm ReLU không có đạo hàm tại \\(s = 0\\), trong thực nghiệm, người ta vẫn thường định nghĩa \\(\text{ReLU}'(0) = 0\\) và khẳng định thêm rằng, xác suất để input của một unit bằng 0 là rất nhỏ.


Hàm ReLU có nhiều biến thể khác như [Noisy ReLU, Leaky ReLu, ELUs](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)). Tôi xin phép dừng phần này ở đâu vì chưa có ý định đi sâu vào Deep Neural Networks.

<a name="mot-vai-luu-y"></a>

#### Một vài lưu ý

* Output layer nhiều khi không có activation function mà sử dụng trực tiếp giá trị đầu vào \\(z_i^{(l)}\\) của mỗi unit. Hoặc nói một cách khác, activation function chính là hàm _identity_, tức đầu ra bằng đầu vào.

* Mặc dù activation function cho mỗi unit có thể khác nhau, trong cùng một network, activation như nhau thường được sử dụng. Điều này giúp cho việc tính toán được đơn giản.


<a name="backpropagation"></a>

## Backpropagation
Phương pháp phổ biến nhất để tối ưu MLP vẫn là Gradient Descent (GD). Để áp dụng GD, chúng ta cần tính được gradient của hàm mất mát theo từng ma trận trọng số \\(\mathbf{W}^{(l)}\\) và vector bias \\(\mathbf{b}^{(l)}\\). Trước hết, chúng ta cần tính _predicted output_ \\( \mathbf{\hat{y}}\\)  với một input \\(\mathbf{x}\\):
\\[
\begin{eqnarray}
\mathbf{a}^{(0)} &=& \mathbf{x} \\\
z_{i}^{(l)} &=& \mathbf{w}_i^{(l)T}\mathbf{a}^{(l-1)} + b\_i^{(l)} \\\
\mathbf{z}^{(l)}  &=& \mathbf{W}^{(l)T}\mathbf{a}^{(l-1)} + \mathbf{b}^{(l)},~~ l =  1, 2, \dots, L \\\
\mathbf{a}^{(l)} &=& f(\mathbf{z}^{(l)}), ~~ l =  1, 2, \dots, L \\\
\mathbf{\hat{y}} &=& \mathbf{a}^{(L)}
\end{eqnarray}
\\]

Giả sử \\(J(\mathbf{W, b, X, Y})\\) là một hàm mất mát của bài toán, trong đó \\(\mathbf{W, b}\\) là tập hợp tất cả các ma trận trọng số giữa các layers và biases của mỗi layer. Để có thể áp dụng các gradient-based methods (mà Gradient Descent là một ví dụ), chúng ta cần tính được:
\\[
\frac{\partial J}{\partial \mathbf{W}^{(l)}} ; \frac{\partial J}{\partial \mathbf{b}^{(l)}},~~ l = 1, 2, \dots, L
\\]

Một ví dụ của hàm mất mát là hàm Mean Square Error (MSE) tức _trung bình của bình phương lỗi_.
\\[
\begin{eqnarray}
J(\mathbf{W, b, X, Y}) &=& \frac{1}{N}\sum\_{i=1}^N \|\| \mathbf{y}\_i - \mathbf{\hat{y}}\_i\|\|\_2^2 \\\
&=&\frac{1}{N}\sum\_{i=1}^N \|\| \mathbf{y}_i - \mathbf{z}\_i^{(L)}\|\|\_2^2
\end{eqnarray}
\\]
Với \\(N\\) là số cặp dữ liệu \\((\mathbf{x}, \mathbf{y})\\) trong tập training.

Theo những công thức ở trên, việc tính toán trực tiếp giá trị này là cực kỳ phức tạp. Và một phương pháp phổ biến được dùng có tên là Backpropagation giúp tính gradient ngược từ layer cuối cùng đến layer đầu tiên. Layer cuối cùng được tính toán trước vì nó _gần gũi_ hơn với _predicted outputs_ và hàm mất mát. Việc tính toán gradient của các layer trước được thực hiện dựa trên một quy tắc quen thuộc có tên là _chain rule_, tức _đạo hàm của hàm hợp_.

Stochastic Gradient Descent có thể được sử dụng để tính gradient cho các ma trận trọng số và biases dựa trên một cặp điểm training \\(\mathbf{x, y}\\). Để cho đơn giản, ta coi \\(J\\) là hàm mất mát nếu chỉ xét cặp điểm này, ở đây \\(J\\) là hàm mất mát bất kỳ, không chỉ hàm MSE như ở trên.

Đạo hàm của hàm mất mat theo _chỉ một thành phần_ của ma trận trọng số của lớp cuối cùng:

\\[
\begin{eqnarray}
\frac{\partial J}{\partial w_{ij}^{(L)}} &=& \frac{\partial J}{\partial z_i^{(L)}}. \frac{\partial z_i^{(L)}}{\partial w_{ij}^{(L)}} \\\
&=& e_i^{(L)} a_j^{(L-1)}
\end{eqnarray}
\\]

Trong đó \\(e_i^{(L)} = \frac{\partial J}{\partial z_i^{(L)}} \\) thường là một đạilượng dễ tính toán và \\(\frac{\partial z_i^{(L)}}{\partial w_{ij}^{(L)}}  = a_j^{(L-1)}\\) vì \\(z_i^{(L)} = \mathbf{w}_i^{(L-1)T}\mathbf{a}^{(L-1)} + b_i^{(L-1)}\\).

Tương tự như thế, đạo hàm của hàm mất mat theo bias của layer cuối cùng là:
\\[
\frac{\partial J}{\partial b_{i}^{(L)}} = \frac{\partial J}{\partial z_i^{(L)}}. \frac{\partial z_i^{(L)}}{\partial b_{i}^{(L)}} = e_i^{(L)}
\\]

Với đạo hàm theo hệ số ở các lớp \\(l\\) _thấp hơn_, chúng ta hay xem hình dưới đây. Ở đây, tại mỗi unit, tôi đã viết riêng đầu vào \\(z\\) và đầu ra \\(a\\) để các bạn tiện theo dõi.
<hr>
<div class="imgcap">
 <img src ="/assets/14_mlp/backpropagation.png" align = "center" width = "600">
 <div class = "thecap">Hình : Backpropagation.</div>
</div>
<hr>

Dựa vào hính trên , ta có thể tính được:

\\[
\begin{eqnarray}
\frac{\partial J}{\partial w_{ij}^{(l)}} &=& \frac{\partial J}{\partial z_i^{(l)}}. \frac{\partial z_i^{(l)}}{\partial w_{ij}^{(l)}} \\\
&=& e_i^{(l)} a_j^{(l-1)}
\end{eqnarray}
\\]
với:

\\[
\begin{eqnarray}
e_i^{(l)} &=& \frac{\partial J}{\partial z_i^{(l)}} = \frac{\partial J}{\partial a_i^{(l)}} . \frac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \\\
&=& \left( \sum_{k = 1}^{d^{(l+1)}} \frac{\partial J}{\partial z_k^{(l+1)}} .\frac{\partial z_k^{(l+1)}}{\partial a_i^{(l)}} \right) f'(z_i^{(l)}) \\\
 &=&\left( \sum_{k = 1}^{d^{(l+1)}} e_k^{(l+1)} w_{ki}^{(l+1)} \right) f'(z_i^{(l)}) \\\
 &=&\left( \mathbf{w}_i^{(l+1)T} \mathbf{e}^{(l+1)} \right) f'(z_i^{(l)}) \\\
\end{eqnarray}
\\]

trong đó \\(\mathbf{e}^{(l+1)} = [e_1^{(l+1)}, e_2^{(l+1)}, ..., e_{d^{(l+1)}}^{(l+1)}]^T \in \mathbb{R}^{d^{(l+1)}\times 1} \\).

Dấu sigma tính tổng ở hàng thứ hai trong phép tính trên xuất hiện vì \\(a_{i}^{(l)}\\) _đóng góp_ vào việc tính tất cả các \\(z_k^{(l+1)}\\). Biểu thức đạo hàm ngoài căn đơn giản là vì \\(a_i^{(l)}  = f(z_i^{(l)})\\). Tới đây, ta có thể thấy rằng việc activation function có đạo hàm đơn giản sẽ có ích rất nhiều trong việc tính toán.

Với cách làm tương tự, bạn đọc có thể suy ra:
\\[
\frac{\partial J}{\partial b_i^{(l)}} = e_i^{(l)}
\\]

Nhận thấy rằng trong các công thức trên đây, việc tính các \\(e_i^{(k)}\\) đóng một vài trò quan trọng. Hơn nữa, để tính được giá trị này, ta cần tính được các \\(e_k^{(l+1)}\\). Nói cách khác, ta cần tính _ngược_ các giá trị này từ cuối. Cái tên _backpropagation_ cũng xuất phát từ việc này.

Việc tính toán các đạo hàm khi sử dụng SGD có thể tóm tắt như sau:

<a name="backpropagation-cho-mot-cap-diem-du-lieu"></a>

### Backpropagation cho Stochastic Gradient Descent

#### Đạo hàm theo từng hệ số \\(w_{ij}^{(l)}, b_{i}^{(l)}\\)
<hr>
1. Bước feedforward: Với 1 giá trị đầu vào \\(\mathbf{x}\\), tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các _activation_ \\(\mathbf{a}^{(l)}\\) tại mỗi layer.

2. Với mỗi unit ở output layer, tính \\(e_i^{(L)} = \frac{\partial J}{\partial z_i^{(L)}}\\). Từ đó suy ra:

\\[
\begin{eqnarray}
\frac{\partial J}{\partial w_{ij}^{(L)}} &=& e_i^{(L)} a_j^{(L-1)}\\\
\frac{\partial J}{\partial b_{i}^{(L)}} &=& e_i^{(L)}
\end{eqnarray}
\\]
3. Với \\(l = L-1, L-2, ..., 1\\), tính:
\\[
e_i^{(l)} = \left( \mathbf{w}_i^{(l+1)T} \mathbf{e}^{(l+1)} \right) f'(z_i^{(l)})
\\]
4. Cập nhật đạo hàm cho từng hệ số trong các layer trước:
\\[
\begin{eqnarray}
\frac{\partial J}{\partial w_{ij}^{(l)}} &=& e_i^{(l)} a_j^{(l-1)}\\\
\frac{\partial J}{\partial b_{i}^{(l)}} &=& e_i^{(l)}
\end{eqnarray}
\\]

<hr>

#### Đạo hàm theo ma trận \\(\mathbf{W}^{(l)}, \mathbf{b}^{(l)}\\)
Việc tính toán theo từng hệ số như trên chỉ phù hợp cho việc hiểu nguyên lý tính toán, trong khi lập trình, ta cần tìm cách thu gọn chúng về dạng vector và ma trận để tăng tốc độ cho thuật toán. Đặt \\(\mathbf{e}^{(l)} = [e_1^{(l)}, e_2^{(l)}, ..., e_{d^{(l)}}^{(l)}]^T \in \mathbb{R}^{d^{(l)}\times 1} \\). Ta sẽ có quy tắc tính như sau:

<hr>
1. Bước feedforward: Với 1 giá trị đầu vào \\(\mathbf{x}\\), tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các _activation_ \\(\mathbf{a}^{(l)}\\) tại mỗi layer.
2. Với mỗi unit ở output layer, tính: \\[\mathbf{e}^{(L)} = \frac{\partial J}{\partial \mathbf{z}^{(L)}}\\]
Từ đó suy ra:
\\[
\begin{eqnarray}
\frac{\partial J}{\partial \mathbf{W}^{(L)}} &=& \mathbf{e}^{(L)} \mathbf{a}^{(L-1)T}\\\
\frac{\partial J}{\partial b_{i}^{(L)}} &=&  \mathbf{e}^{(L)}
\end{eqnarray}
\\]
3. Với \\(l = L-1, L-2, ..., 1\\), tính:
\\[
\mathbf{e}^{(l)} = \left( \mathbf{W}^{(l+1)T} \mathbf{e}^{(l+1)} \right) \odot f'(\mathbf{z}^{(l)})
\\]
trong đó \\(\odot\\) là _element-wise product_ hay _Hadamard product_ tức lấy từng thành phần của hai vector nhân với nhau để được vector kết quả.
4. Cập nhật đạo hàm cho ma trận trọng số và vector biases:
\\[
\begin{eqnarray}
\frac{\partial J}{\partial \mathbf{W}^{(l)}} &=& \mathbf{e}^{(l)T}\mathbf{a}^{(l-1)}\\\
\frac{\partial J}{\partial \mathbf{b}^{(l)}} &=& \mathbf{e}^{(l)}
\end{eqnarray}
\\]

<hr>

### Backpropagation cho Batch (mini-batch) Gradient Descent

Nếu chúng ta muốn thực hiện Batch hoặc mini-batch Gradient Descent thì sao (trong thực tế, mini-batch) GD được sử dụng nhiều nhất.

Khi đó, cặp (input, output) sẽ ở dạng ma trận \\((\mathbf{X, Y}\\). Giả sử rằng mỗi lần tính toán, ta lấy \\(N\\) dữ liệu để tính toán. Khi đó, \\(\mathbf{X} \in \mathbb{R}^{d \times N}, \mathbf{Y} \in \mathbf{d^{(L)}\times N\\). Với \\(d\\) là số chiều của dữ liệu đầu vào (không tính bias).

 Khi đó các activation sau mỗi layer sẽ có dạng \\(\mathbf{A}^{(l)} \in \mathbb{R}^{d^{(l)} \times N}\\). Tương tự thế, \\(\mathbf{E}^{(l)} \in \mathbb{R}^{d^{(l)}\times N}\\). Và ta cũng có thể suy ra công thức cập nhật như sau.

 <hr>
 1. Bước feedforward: Với toàn bộ dữ liệu (batch) hoặc một nhóm dữ liệu (mini-batch) đầu vào \\(\mathbf{X}\\), tính giá trị đầu ra của network, trong quá trình tính toán, lưu lại các _activation_ \\(\mathbf{A}^{(l)}\\) tại mỗi layer.
 2. Với mỗi unit ở output layer, tính: \\[\mathbf{E}^{(L)} = \frac{\partial J}{\partial \mathbf{Z}^{(L)}}\\]
 Từ đó suy ra:
 \\[
 \begin{eqnarray}
 \frac{\partial J}{\partial \mathbf{W}^{(L)}} &=& \mathbf{E}^{(L)T} \mathbf{A}^{(L-1)}\\\
 \frac{\partial J}{\partial b_{i}^{(L)}} &=&  \sum_{i=1}^N \mathbf{e}_i^{(L)}
 \end{eqnarray}
 \\]
 3. Với \\(l = L-1, L-2, ..., 1\\), tính:
 \\[
 \mathbf{e}^{(l)} = \left( \mathbf{W}^{(l+1)T} \mathbf{e}^{(l+1)} \right) \odot f'(\mathbf{z}^{(l)})
 \\]
 trong đó \\(\odot\\) là _element-wise product_ hay _Hadamard product_ tức lấy từng thành phần của hai vector nhân với nhau để được vector kết quả.
 4. Cập nhật đạo hàm cho ma trận trọng số và vector biases:
 \\[
 \begin{eqnarray}
 \frac{\partial J}{\partial \mathbf{W}^{(l)}} &=& \mathbf{e}^{(l)T}\mathbf{a}^{(l-1)}\\\
 \frac{\partial J}{\partial \mathbf{b}^{(l)}} &=& \mathbf{e}^{(l)}
 \end{eqnarray}
 \\]

 <hr>
<a name="tai-lieu-tham-khao"></a>

## Tài liệu tham khảo

http://cs231n.github.io/neural-networks-1/

http://cs231n.github.io/neural-networks-case-study/
