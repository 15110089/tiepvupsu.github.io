---
layout: post
comments: true
title:  "Bài 31: Maximum Likelihood và Maximum a Posteriori estimation"
title2:  "31. Maximum Likelihood và Maximum a Posteriori"
date:   2017-07-15 15:22:00
permalink: 2017/07/15/mlmap/
mathjax: true
tags: Probability
category: Bayesian-Models
sc_project: 
sc_security: 
img: 
summary: 
---
**Trong trang này:**

<!-- MarkdownTOC -->

- [Giới thiệu](#gioi-thieu)
- [2. Maximum Likelihood Estimation](#-maximum-likelihood-estimation)
  - [Ý tưởng](#y-tuong)
  - [Independence Assumption và log-likelihood](#independence-assumption-va-log-likelihood)
  - [Ví dụ](#vi-du)

<!-- /MarkdownTOC -->

<a name="gioi-thieu"></a>

## Giới thiệu
**Những sự kiện có xác suất cao là những sự kiện có khả năng xảy ra hơn.** 

Câu nói _nói cũng như không này_ là khơi nguồn cho rất nhiều các thuật toán Machine Learning có liên quan đến xác suất. 

Cách giải quyết bài toán Machine Learning có thể viết gọn lại thành 3 bước chính: **Modeling, Learning** và **Inference**. (Xem [Computer Vision: Models, Learning, and Inference](http://www.computervisionmodels.com/))

**Modeling là việc đi tìm môt mô hình thích hợp cho bài toán cần giải quyết.** Với bài toán [Linear Regression](https://machinelearningcoban.com/2016/12/28/linearregression/), modeling chính là việc mô hình dữ liệu đầu ra (output) như là tổ hợp tuyến tính của dữ liệu đầu vào (input). Với bài toán [k-means clustering](http://127.0.0.1:4000/2017/01/01/kmeans/), modeling chính là việc quan sát ra rằng các clusters thường được mô tả bởi các _centroids_ (hoặc _centers_) và mỗi điểm được xếp vào cluster tương ứng với centroid gần nó nhất. Trong bài toán [Support Vector Machine](http://127.0.0.1:4000/2017/04/09/smv/) cho dữ liệu linearly separable, modeling chính là bước quan sát thấy rằng đường thằng phân chia hai classes phải là đường làm cho margin đạt giá trị lớn nhất. Việc đi tìm ra mô hình nào phù hợp cho bài toán chính là bước **Modeling**. 

**Learning là bước tiến hành tối ưu các tham số của mô hình.** Mỗi model được mô hình bởi một bộ các tham số (parameters). Với Linear Regression, tham số mô hình là bộ vector hệ số và bias \\((\mathbf{w}, b)\\). Với K-means clustering, tham số mô hình có thể được coi là các clusters. Với Support Vector Machine, tham số mô hình có thể là vector hệ số và bias mô tả đường thằng \\((\mathbf{w}, b)\\). Việc đi tìm các tham số cho mô hình thường được thực hiện bằng việc giải một bài toán tối ưu. Quá trình giải bài toán tối ưu, hay chính là quá trình đi tìm tham số của mô hình, chính là quá trình **Learning**. Sau bước Learning này, chúng ta thu được các _trained parameters_.

**Inference là bước dự đoán ouput của mô hình dựa trên các trained parameters.** Với Linear Regression, Inference chính là việc tính \\(y = \mathbf{w}^T\mathbf{x} + b\\) dựa trên bộ các tham số đã được huấn luyện \\((\mathbf{w}, b)\\). Với K-means clustering, việc inference chính là việc đi tìm centroid gần nhất. Với Support Vector Machine, Inference chính là việc xác định class của một dữ liệu mới dựa vào công thức \\(y = \text{sgn}(\mathbf{w}^T\mathbf{x} + b)\\). So với hai bước Modeling và Learning, Inference thường đơn giản hơn. 

Như đã đề cập, ở nửa sau của blog, tôi sẽ giới thiệu rất nhiều các mô hình thống kê. Trong các mô hình này, việc _Modeling_ là việc đi tìm một mô hình thống kê (statistical model) phù hợp với từng loại dữ liệu và bài toán. Việc _Learning_ là việc đi tìm các tham số cho mô hình thống kê đó. Việc _Inference_ có thể coi là việc tính xác suất để xảy ra mỗi giá trị ở đầu ra khi biết các giá trị ở đầu vào và model được mô tả bởi các trained parameters. 

Các Mô Hình Thống Kê (Statistical Models) thường là sự kết hợp của các [phân phối xác suất đơn giản](http://127.0.0.1:4000/2017/07/09/prob/#-mot-vai-xac-suat-thuong-gap.). Với [Bernouli distribution](http://127.0.0.1:4000/2017/07/09/prob/#-bernouli-distribution), tham số là biến \\(\lambda\\). Với [Multivariate Normal Distribution](http://127.0.0.1:4000/2017/07/09/prob/#-multivariate-normal-distribution), tham số là mean vector \\(\mu\\) và ma trận hiệp phương sai \\(\Sigma\\). Với một mô hình thông kê bất kỳ, ký hiệu \\(\theta\\) là tập hợp tất cả các tham số của mô hình đó. Learning chính là quá trình đánh giá (estimate) bộ tham số \\(\theta\\) sao cho dữ liệu sẵn có và mô hình *khớp* với nhau nhất. Quá trình đó còn được gọi là _parameter estimation_. 

Có hai cách đánh giá tham số thường được dùng trong Statistical Machine Learning. Cách thứ nhất chỉ dựa trên dữ liệu đã biết trong tập traing (training data), được gọi là _Maximum Likelihood Estimation_ hay _ML Estimation_ hoặc _MLE_. Cách thứ hai không những dựa trên training data mà còn dựa trên những thông tin đã biết của các tham số. Những thông tin này có thể có được bằng _cảm quan_ của người xây dựng mô hình. _Cảm quan_ càng rõ ràng, càng hợp lý thì khả năng thu được bộ tham số tốt là càng cao. Chẳng hạn, thông tin biết trước của \\(\lambda\\) trong Bernouli distribution là việc nó là một số trong đoạn \\([0, 1]\\). Với bài toán tung đồng xu, với \\(\lambda\\) là xác suất có được mặt _head_, ta dự đoán được rằng giá trị này nên là một số gần với \\(0.5\\). Cách đánh giá tham số thứ hai này được gọi là _Maximum A Posteriori Estimation_ hay _MAP Estimation_.

Trong bài viết này, tôi sẽ trình bày về ý tưởng và cách giải quyết bài toán đánh giá tham số mô hình theo _MLE_ hoặc _MAP Estimation_. Và như thường lệ, chúng ta sẽ cùng thực hiện mộ vài ví dụ đơn giản. 

<a name="-maximum-likelihood-estimation"></a>

## 2. Maximum Likelihood Estimation

<a name="y-tuong"></a>

### Ý tưởng 
Giả sử có các điểm dữ liệu \\(\mathbf{x}\_1, \mathbf{x}\_2, \dots, \mathbf{x}\_N\\). Với các bài toán Supervised Learning, mỗi điểm dữ liệu này có thể coi như đã bao gồm cả đầu ra. 

Maximum Likelihood Estimation là việc đi tìm bộ tham số \\(\theta\\) sao cho xác suất sau đây đạt giá trị lớn nhất:

\\[
\theta = \max_{\theta} p(\mathbf{x}\_1, \dots, \mathbf{x}\_N | \theta) ~~~~ (1)
\\]

Biểu thức \\((1)\\) có ý nghĩa như thế nào và vì sao việc này có lý? 

Giả sử rằng ta đã biết mô hình rồi, và mô hình này được mô tả bởi bộ tham số \\(\theta\\). Thế thì, \\(p(\mathbf{x}\_1 \| \theta)\\) chính là xác suất xảy ra _sự kiện_ \\(\mathbf{x}\_1\\) biết rằng mô hình là (được mô tả bởi) \\(\theta\\) (đây là một [conditional probability](http://127.0.0.1:4000/2017/07/09/prob/#-conditional-probability)). Và \\(p(\mathbf{x}\_1, \dots, \mathbf{x}\_N \| \theta)\\) chính là xác suất để toàn bộ các _sự kiện_ \\(\mathbf{x}\_1, \mathbf{x}\_2, \dots, \mathbf{x}\_N\\) xảy ra đồng thời (nó là một [joint probability](http://127.0.0.1:4000/2017/07/09/prob/#-joint-probability)), xác suất đồng thời này còn được gọi là _likelihood_. Ở đây, _likelihood_ chính là hàm mục tiêu. 

Bởi vì _sự đã rồi_, tức dữ liệu training bản thân nó đã là như thế rồi, xác suất đồng thời này cần phải càng cao càng tốt. Việc này cũng giống như việc đã biết _kết quả_, và ta cần đi tìm _nguyên nhân_ sao cho xác suất xảy ra kết quả này càng cao càng tốt. 

Maximum Likelihood chính là việc đi tìm bộ tham số \\(\theta\\) sao cho Likelihood là lớn nhất. 

<a name="independence-assumption-va-log-likelihood"></a>

### Independence Assumption và log-likelihood
Việc giải trực tiếp bài toán \\((1)\\) thường là phức tạp vì việc đi tìm mô hình xác suất đồng thời cho toàn bộ dữ liệu là ít khi khả thi. Một cách tiếp cận phổ biến là dựa trên giả sử đơn giản rằng các điểm dữ liệu \\(\mathbf{x}\_n\\) là [độc lập](http://127.0.0.1:4000/2017/07/09/prob/#-independence), hoặc gần như độc lập, với nhau. Nói các khác, ta xấp xỉ likelihood trong \\((1)\\) bởi: 
\\[
p(\mathbf{x}\_1, \dots, \mathbf{x}\_N | \theta) \approx \prod_{n = 1}^N p(\mathbf{x}\_n \|\theta) ~~~~ (2)
\\]

(Nhắc lại rằng hai sự kiện \\(x, y\\) là độc lập nếu xác suất đồng thời của chúng bằng tích xác suất của từng sự kiện: \\(p(x, y) = p(x)p(y)\\). Và khi là xác suất có điều kiện: \\(p(x, y \| z) = p(x\|z)p(y\|z)\\))

Lúc đó, bài toán \\((1)\\) có thể được giải quyết bằng cách giải bài toán tối ưu sau: 

\\[
\theta = \max_{\theta} \prod_{n=1}^N p(\mathbf{x}\_n| \theta) ~~~~ (3)
\\]

Việc tối ưu hoá một tích thường phức tạp hơn việc tối ưu một tổng, vì vậy việc tối đa hàm mục tiêu thường được chuyển về việc tối đa \\(\log\\) của hàm mục tiêu. Ôn lại một chút: 

* \\(\log\\) của một tích bằng tổng của các \\(\log\\).

* vì rằng \\(\log\\) là một hàm đồng biến, một biểu thức sẽ là lớn nhất nếu \\(\log\\) của nó là lớn nhất, và ngược lại. 

Bài toán Maximum Likelihood được đưa về bài toán Maximum Log-likelihood:
\\[
\theta = \max_{\theta} \sum_{n = 1}^N \log\left\(p(\mathbf{x}\_n \| \theta)\right\) ~~~~ (4)
\\]

Bạn vẫn chưa hiểu? Không lo, bây giờ chúng ta sẽ làm vài ví dụ.

<a name="vi-du"></a>

### Ví dụ 








